{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb54de36-1c17-4e1f-a8b8-06c388771c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 14:37:07.825418: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.879465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.879673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.881958: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.882138: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.882269: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.993428: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.993757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.993817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-08 14:37:07.993934: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 14:37:07.994057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3654 MB memory:  -> device: 0, name: Orin, pci bus id: 0000:00:00.0, compute capability: 8.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762609031.816507  121921 service.cc:145] XLA service 0xfffe64007aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762609031.816573  121921 service.cc:153]   StreamExecutor device (0): Orin, Compute Capability 8.7\n",
      "2025-11-08 14:37:11.864001: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-08 14:37:12.096974: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/60\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.6075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762609032.638149  121921 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - loss: 20.3244 - val_loss: 17.4276\n",
      "Epoch 2/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 16.4403 - val_loss: 16.2792\n",
      "Epoch 3/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 15.2979 - val_loss: 15.1363\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9306 - val_loss: 13.5258\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.1102 - val_loss: 11.2863\n",
      "Epoch 6/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6627 - val_loss: 8.4197\n",
      "Epoch 7/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.7361 - val_loss: 5.2961\n",
      "Epoch 8/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.7961 - val_loss: 2.6705\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8433 - val_loss: 1.4168\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1370 - val_loss: 1.0201\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9178 - val_loss: 0.8570\n",
      "Epoch 12/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7936 - val_loss: 0.7465\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6957 - val_loss: 0.6538\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6136 - val_loss: 0.5734\n",
      "Epoch 15/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5394 - val_loss: 0.5036\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4706 - val_loss: 0.4422\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4053 - val_loss: 0.3857\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3511 - val_loss: 0.3373\n",
      "Epoch 19/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3048 - val_loss: 0.2939\n",
      "Epoch 20/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2644 - val_loss: 0.2557\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2306 - val_loss: 0.2237\n",
      "Epoch 22/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2032 - val_loss: 0.1967\n",
      "Epoch 23/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1814 - val_loss: 0.1757\n",
      "Epoch 24/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1630 - val_loss: 0.1572\n",
      "Epoch 25/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1470 - val_loss: 0.1416\n",
      "Epoch 26/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1339 - val_loss: 0.1295\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1228 - val_loss: 0.1196\n",
      "Epoch 28/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1137 - val_loss: 0.1115\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1055 - val_loss: 0.1048\n",
      "Epoch 30/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0987 - val_loss: 0.0987\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0923 - val_loss: 0.0932\n",
      "Epoch 32/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0869 - val_loss: 0.0877\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0818 - val_loss: 0.0819\n",
      "Epoch 34/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0772 - val_loss: 0.0768\n",
      "Epoch 35/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0729 - val_loss: 0.0723\n",
      "Epoch 36/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0689 - val_loss: 0.0680\n",
      "Epoch 37/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0654 - val_loss: 0.0637\n",
      "Epoch 38/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0624 - val_loss: 0.0604\n",
      "Epoch 39/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0596 - val_loss: 0.0576\n",
      "Epoch 40/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0574 - val_loss: 0.0547\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.0523\n",
      "Epoch 42/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0534 - val_loss: 0.0504\n",
      "Epoch 43/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0514 - val_loss: 0.0485\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0496 - val_loss: 0.0467\n",
      "Epoch 45/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0477 - val_loss: 0.0449\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.0435\n",
      "Epoch 47/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0444 - val_loss: 0.0427\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.0417\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0411 - val_loss: 0.0408\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0399\n",
      "Epoch 51/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0387\n",
      "Epoch 52/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0378\n",
      "Epoch 53/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.0370\n",
      "Epoch 54/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.0362\n",
      "Epoch 55/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.0350\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.0342\n",
      "Epoch 57/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.0335\n",
      "Epoch 58/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0330\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0324\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.0321\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0316\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0312\n",
      "Epoch 63/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0310\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0306\n",
      "Epoch 65/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0301\n",
      "Epoch 66/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0293\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0288\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0286\n",
      "Epoch 70/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0284\n",
      "Epoch 71/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0223 - val_loss: 0.0285\n",
      "Epoch 72/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0219 - val_loss: 0.0282\n",
      "Epoch 73/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0215 - val_loss: 0.0284\n",
      "Epoch 74/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0285\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0285\n",
      "Epoch 76/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0281\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0280\n",
      "Epoch 78/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0277\n",
      "Epoch 79/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0273\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0273\n",
      "Epoch 81/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0267\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179 - val_loss: 0.0261\n",
      "Epoch 83/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174 - val_loss: 0.0255\n",
      "Epoch 84/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0247\n",
      "Epoch 85/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0237\n",
      "Epoch 86/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0160 - val_loss: 0.0231\n",
      "Epoch 87/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0156 - val_loss: 0.0221\n",
      "Epoch 88/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - val_loss: 0.0215\n",
      "Epoch 89/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 90/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - val_loss: 0.0205\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0144 - val_loss: 0.0201\n",
      "Epoch 92/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - val_loss: 0.0194\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0139 - val_loss: 0.0185\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - val_loss: 0.0175\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 96/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - val_loss: 0.0164\n",
      "Epoch 97/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 98/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 99/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - val_loss: 0.0154\n",
      "Epoch 100/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - val_loss: 0.0151\n",
      "Epoch 102/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - val_loss: 0.0145\n",
      "Epoch 103/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - val_loss: 0.0141\n",
      "Epoch 104/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0110 - val_loss: 0.0136\n",
      "Epoch 105/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 106/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 107/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 108/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 109/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 111/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 112/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0111\n",
      "Epoch 113/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0109\n",
      "Epoch 114/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 116/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0107\n",
      "Epoch 117/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 118/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 119/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 120/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 121/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 122/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 123/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 124/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 125/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 126/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0097\n",
      "Epoch 127/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 128/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 129/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0092\n",
      "Epoch 130/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0091\n",
      "Epoch 131/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 132/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 133/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 134/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 135/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 136/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0082\n",
      "Epoch 137/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 138/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 139/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 140/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 141/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0078\n",
      "Epoch 142/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 143/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 144/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 145/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 146/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 147/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 148/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 149/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 150/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 151/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 152/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 153/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 154/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 155/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 156/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 157/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Epoch 158/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 159/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 160/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 161/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 162/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 163/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 24.2933 - val_loss: 20.2776\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.1173 - val_loss: 16.5322\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.9259 - val_loss: 15.3507\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.5147 - val_loss: 13.6625\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.5631 - val_loss: 11.2559\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7575 - val_loss: 7.9789\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3695 - val_loss: 4.6738\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6927 - val_loss: 2.4716\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4765 - val_loss: 1.5667\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0661 - val_loss: 1.1989\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8806 - val_loss: 0.9896\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7483 - val_loss: 0.8325\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6385 - val_loss: 0.7100\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5448 - val_loss: 0.6127\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4669 - val_loss: 0.5307\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4018 - val_loss: 0.4590\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3489 - val_loss: 0.3982\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3055 - val_loss: 0.3476\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2684 - val_loss: 0.3091\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2374 - val_loss: 0.2757\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2106 - val_loss: 0.2476\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1887 - val_loss: 0.2255\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1701 - val_loss: 0.2084\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1545 - val_loss: 0.1924\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1412 - val_loss: 0.1787\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1293 - val_loss: 0.1665\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1191 - val_loss: 0.1558\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1095 - val_loss: 0.1451\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1009 - val_loss: 0.1359\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0932 - val_loss: 0.1273\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0864 - val_loss: 0.1192\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0802 - val_loss: 0.1115\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0749 - val_loss: 0.1047\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0702 - val_loss: 0.0980\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0658 - val_loss: 0.0922\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.0876\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0585 - val_loss: 0.0833\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0554 - val_loss: 0.0792\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0527 - val_loss: 0.0756\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0501 - val_loss: 0.0726\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0478 - val_loss: 0.0694\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.0669\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0434 - val_loss: 0.0645\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0415 - val_loss: 0.0625\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0604\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0382 - val_loss: 0.0588\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0572\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0355 - val_loss: 0.0557\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0341 - val_loss: 0.0540\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0328 - val_loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capybara/Desktop/matura_project_python/github/matura/FNN1_1.py:246: RuntimeWarning: divide by zero encountered in divide\n",
      "  relativeError = np.where(np.array(y_test) != 0, deviation.flatten() / np.abs(np.array(y_test)), deviation.flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here they are: 0.02929296649786832, 11.328839396768844, 15.345475817041319, 0.0405685937854541\n",
      "2 - -1 + 4\n",
      "2543\n",
      "7.0\n",
      "\n",
      "Expressions not in x:\n",
      "-4 - -5 + -1\n",
      "True\n",
      "1457\n",
      "0.0\n",
      "15\n",
      "-4.0\n",
      "[-5.   1.   1.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"g4gLSTM.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation\n",
    "print(f\"Here they are: {baseline_deviation}, {baseline_out_deviation}, {baseline_long_deviation}, {baseline_relError}\")\n",
    "# Now you can import from GetXY.py\n",
    "from GetXY import x_train, y_train, x_val, y_val, x_test, y_test, out_x_test, out_y_test, long_x_test, long_y_test, outsideExpr, absSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5505dc-debc-4d51-8707-9f9dcf8c4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable weights for attention mechanism\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        self.u = self.add_weight(name=\"att_u\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Score computation\n",
    "        v = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        vu = tf.tensordot(v, self.u, axes=1)\n",
    "        alphas = tf.nn.softmax(vu)\n",
    "\n",
    "        # Weighted sum of input\n",
    "        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), axis=1)\n",
    "        return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5ddb3e-fff3-403e-9e7a-e90272a0e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_attention_model(input_shape, lstm_units):\n",
    "    inputs = keras.Input(shape=(input_shape, 1))\n",
    "    \n",
    "    # Bi-LSTM layer\n",
    "    lstm_out = keras.layers.LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    \n",
    "    # Add Attention layer\n",
    "    attention_out, attention_weights = AttentionLayer()(lstm_out)\n",
    "    \n",
    "    # Final Dense layer\n",
    "    outputs = keras.layers.Dense(1, activation=\"linear\")(attention_out)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbc8430-b852-4a70-a749-d78624992bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 5\n",
    "min_neurons = 35\n",
    "max_neurons = 35\n",
    "neuron_step = 1\n",
    "min_layers = 2\n",
    "max_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288ccf6f-f2de-4d87-9196-41ba8d4b8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73eb958-830a-4a1e-a87e-e81a0754f060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "bootstrap_predsInRange = []\n",
    "bootstrap_predsOutRange = []\n",
    "bootstrap_predsLongRange = []\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            early_stopping = keras.callbacks.EarlyStopping(\n",
    "                patience=5,\n",
    "                min_delta=0.001,\n",
    "                restore_best_weights=True,\n",
    "                monitor='mse',\n",
    "                mode = \"min\"\n",
    "            )           \n",
    "            sample_indices = np.random.choice(len(x_train), size=len(x_train), replace=True)\n",
    "            x_train_bootstrap = x_train[sample_indices]\n",
    "            y_train_bootstrap = np.array(y_train)[sample_indices]\n",
    "            bootstrap_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_bootstrap, y_train_bootstrap)).batch(32)\n",
    "\n",
    "            #bootstrap_model = build_model(len(x_train[0]), l, n)\n",
    "            bootstrap_model = build_lstm_attention_model(len(x_train[0]),n)\n",
    "\n",
    "            bootstrap_model.compile(optimizer = \"adam\", loss = \"mse\", metrics=['mse'])\n",
    "            \n",
    "            bootstrap_model.fit(\n",
    "            bootstrap_train_dataset,\n",
    "            epochs=100,\n",
    "            verbose=0, # Suppress output\n",
    "            callbacks=[early_stopping]\n",
    "            )\n",
    "\n",
    "            bootstrap_predsInRange.append(bootstrap_model.predict(x_test))\n",
    "            bootstrap_predsOutRange.append(bootstrap_model.predict(out_x_test))\n",
    "            bootstrap_predsLongRange.append(bootstrap_model.predict(long_x_test))\n",
    "\n",
    "bootstrap_predsInRange = np.array(bootstrap_predsInRange)\n",
    "bootstrap_predsOutRange = np.array(bootstrap_predsOutRange)\n",
    "\n",
    "bootstrap_predsLongRange = np.array(bootstrap_predsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d19a48-d6bc-4977-add8-4d6b8600dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,180</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_4               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,295</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m)         │         \u001b[38;5;34m5,180\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_4               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m1,295\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │ \u001b[38;5;34m15\u001b[0m)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,535</span> (76.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,535\u001b[0m (76.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,511</span> (25.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,511\u001b[0m (25.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,024</span> (50.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m13,024\u001b[0m (50.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bootstrap_predsInRange.shape\n",
    "bootstrap_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbff871c-ce79-42e9-9c59-4e0a3978c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = int(bootstrap_predsInRange.shape[0]/n_bootstrap)\n",
    "mean_modelpredsInRange = []\n",
    "mean_modelpredsOutRange = []\n",
    "mean_modelpredsLongRange = []\n",
    "\n",
    "for model_index in range(num_models):\n",
    "    model_predsInRange = bootstrap_predsInRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsOutRange = bootstrap_predsOutRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsLongRange = bootstrap_predsLongRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "\n",
    "    mean_modelpredsInRange.append(np.mean(model_predsInRange, axis = 0))\n",
    "    mean_modelpredsOutRange.append(np.mean(model_predsOutRange, axis = 0))\n",
    "    mean_modelpredsLongRange.append(np.mean(model_predsLongRange, axis = 0))\n",
    "\n",
    "mean_modelpredsInRange = np.array(mean_modelpredsInRange)\n",
    "mean_modelpredsOutRange = np.array(mean_modelpredsOutRange)\n",
    "mean_modelpredsLongRange = np.array(mean_modelpredsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5caaef0-51a6-47c4-8271-f997cc61cee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.76864356], dtype=float32)]\n",
      "[array([0.274358], dtype=float32)]\n",
      "[array([3.6290889], dtype=float32)]\n",
      "[array([0.3479223], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "mean_modelpredsInRange.shape\n",
    "diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  diff_differences.append(calc/len(y_test))\n",
    "print(diff_differences)\n",
    "\n",
    "rel_diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] != 0:\n",
    "        calc += (abs(y_test[i]-mean_modelpredsInRange[j][i])/abs(y_test[i]))\n",
    "    else:\n",
    "        calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  rel_diff_differences.append(calc/len(y_test))\n",
    "print(rel_diff_differences)\n",
    "\n",
    "out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  out_diff_differences.append(calc/len(out_y_test))\n",
    "print(out_diff_differences)\n",
    "\n",
    "rel_out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    if out_y_test[i] != 0:\n",
    "        calc += (abs(out_y_test[i]-mean_modelpredsOutRange[j][i])/abs(out_y_test[i]))\n",
    "    else:\n",
    "        calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  rel_out_diff_differences.append(calc/len(out_y_test))\n",
    "print(rel_out_diff_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc9ea613-d3b6-4ba5-9c40-4c1adfe35b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = absSum(outsideExpr)\n",
    "diff_out_differences = []\n",
    "indices_with_placeholder_22 = [i for i, val in enumerate(placeholder) if val == 22] \n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in indices_with_placeholder_22:\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  diff_out_differences.append(calc/len(indices_with_placeholder_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfc7ff5-3b4f-43ad-9624-7a1b4922b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_out_relError = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(mean_modelpredsOutRange.shape[1]):\n",
    "    calc += abs((out_y_test[i]-mean_modelpredsOutRange[j][i])/out_y_test[i])\n",
    "  diff_out_relError.append(calc/mean_modelpredsOutRange.shape[1])\n",
    "\n",
    "\n",
    "y_test_safe = np.copy(y_test).astype(float) # Ensure float type for division\n",
    "y_test_safe[y_test_safe == 0] = 1\n",
    "diff_relError = np.array(diff_differences) / np.array(y_test_safe)\n",
    "\n",
    "diff_relErrors = (np.array(diff_out_relError) + np.array(diff_relError))/2.0\n",
    "diff_avRelError = np.mean(diff_relErrors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa09f391-1813-455c-bc3a-a1c77ba40962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.8204567], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(200,300):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  diff_long_differences.append(calc/100)\n",
    "\n",
    "meow_diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(long_y_test)):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  meow_diff_long_differences.append(calc/len(long_y_test))\n",
    "print(meow_diff_long_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b9ddb7-dc63-4149-b9f4-65df7911f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(diff_differences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4c869e-4aaf-4eac-ad70-fc06484bd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"transformer0.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b244564-e6f9-4c80-b1f1-75cdcbbddffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.5604553], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "for i in range(len(diff_differences)):\n",
    "  calc = 0\n",
    "  calc += baseline_deviation / (diff_differences[i]**2)\n",
    "  calc += baseline_out_deviation / (diff_out_differences[i]**2)\n",
    "  calc += baseline_long_deviation / (diff_long_differences[i]**2)\n",
    "  calc += baseline_relError / (diff_avRelError[i]**2)\n",
    "  benchmark.append(calc/4)\n",
    "print(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727be262-7945-429c-adf4-b955b9ae5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = (max_neurons - min_neurons) // neuron_step + 1\n",
    "num_layers = max_layers - min_layers + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f33ee47-656c-401e-9e78-ec7a84f66f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new array to include the means\n",
    "# Add a column for row means and a row for column means (and a corner for the overall mean)\n",
    "benchmark_array = np.array(benchmark).reshape(num_layers, num_neurons)\n",
    "extended_benchmark_array = np.zeros((num_layers + 1, num_neurons + 1))\n",
    "\n",
    "Neurons_means = np.mean(benchmark_array, axis=0)\n",
    "Layers_means = np.mean(benchmark_array, axis=1)\n",
    "\n",
    "# Copy the original benchmark data\n",
    "extended_benchmark_array[:num_layers, :num_neurons] = benchmark_array\n",
    "\n",
    "# Add the row means\n",
    "extended_benchmark_array[:num_layers, num_neurons] = Layers_means\n",
    "\n",
    "# Add the column means\n",
    "extended_benchmark_array[num_layers, :num_neurons] = Neurons_means\n",
    "\n",
    "# Calculate and add the overall mean\n",
    "overall_mean = np.mean(benchmark_array)\n",
    "extended_benchmark_array[num_layers, num_neurons] = overall_mean\n",
    "\n",
    "\n",
    "# Create updated tick labels for the heatmap\n",
    "xticklabels_extended = list(np.arange(min_neurons, max_neurons + 1, neuron_step)) + ['Row Mean']\n",
    "yticklabels_extended = list(np.arange(min_layers, max_layers + 1)) + ['Column Mean']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10)) # Adjust figure size for the extra row/column\n",
    "ax = sns.heatmap(extended_benchmark_array, annot=True, fmt=\".2f\", cmap=\"inferno\",\n",
    "            xticklabels=xticklabels_extended,\n",
    "            yticklabels=yticklabels_extended)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.hlines(y=6, xmin=xmin, xmax=xmax, colors='lightblue', lw=2, linestyle='-')\n",
    "ax.vlines(x=11, ymin=ymin, ymax=ymax, colors='lightblue', lw=2, linestyle='-')\n",
    "plt.ylabel('Number of Layers')\n",
    "plt.xlabel('Number of Neurons per Layer')\n",
    "plt.title('Heatmap of the Benchmarks with Row and Column Means')\n",
    "plt.savefig(\"bigHeatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2678ff-6aa5-44db-aae0-90cf9c8a16c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in Range P-value: 0.9704160277916551\n",
      "MRE in Range P-value: 0.02982194832491984\n",
      "MAE out Range P-value: 0.032006552383573646\n",
      "MRE out Range P-value: 0.004111552576025846\n",
      "MAE long Range P-value: 0.009494680929142123\n",
      "Benchmark P-value: 0.2407566416738771\n",
      "\n",
      "Average MAE in Range: 1.0213953357857224\n",
      "Average MRE in Range: 0.3877413113246085\n",
      "Average MAE out Range: 3.9917099986720133\n",
      "Average MRE out Range: 0.41450300850041233\n",
      "Average MAE long Range: 3.1958687173106837\n",
      "Average benchmark: 1.868025656554655\n",
      "\n",
      "MAE in Range List: [0.6903211033111086, 0.30809313053739507, 3.176586190661749, 0.470570535592699, 0.46140571882566034]\n",
      "MRE in Range List: [0.2651481545059261, 0.13742907001938873, 1.1245530612374277, 0.20581001242200156, 0.2057662584382984]\n",
      "MAE out Range List: [3.3797280229628086, 2.7142045014479663, 7.671700686041731, 3.0044511616870295, 3.18846562122053]\n",
      "MRE out Range List: [0.3516941006724351, 0.2567678700848286, 0.8055629262674804, 0.31886974345823216, 0.3396204020190852]\n",
      "MAE long Range List: [3.340606749121632, 2.433453530435051, 4.961458481081895, 2.758297592869827, 2.485527233045016]\n",
      "Benchmark List: [1.0460568078095964, 3.90061741664691, 0.22151534152363098, 1.6720428130004537, 2.4998959037926842]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Initialize lists to store metrics for each bootstrap run\n",
    "MAEinRange_list = []\n",
    "MREinRange_list = []\n",
    "MAEoutRange_list = []\n",
    "MREoutRange_list = []\n",
    "MAElongRange_list = []\n",
    "benchmarks_list = []\n",
    "\n",
    "# Loop through the predictions from each bootstrap run\n",
    "# This assumes the notebook is run with n_bootstrap > 1 for statistical tests\n",
    "for i in range(n_bootstrap):\n",
    "    # Extract predictions for the current run\n",
    "    current_preds_in_range = bootstrap_predsInRange[i]\n",
    "    current_preds_out_range = bootstrap_predsOutRange[i]\n",
    "    current_preds_long_range = bootstrap_predsLongRange[i]\n",
    "\n",
    "    # --- In-Range Metrics ---\n",
    "    diffInRange = np.abs(y_test - current_preds_in_range.flatten())\n",
    "    safe_y_test = np.where(np.isclose(y_test, 0.0), 1.0, y_test)\n",
    "    reldiffInRange = diffInRange / np.abs(safe_y_test)\n",
    "    \n",
    "    mean_mae_in_range = np.mean(diffInRange)\n",
    "    mean_mre_in_range = np.mean(reldiffInRange)\n",
    "    MAEinRange_list.append(mean_mae_in_range)\n",
    "    MREinRange_list.append(mean_mre_in_range)\n",
    "\n",
    "    # --- Out-of-Range Metrics ---\n",
    "    diffOutRange = np.abs(out_y_test - current_preds_out_range.flatten())\n",
    "    safe_out_y_test = np.where(np.isclose(out_y_test, 0.0), 1.0, out_y_test)\n",
    "    reldiffOutRange = diffOutRange / np.abs(safe_out_y_test)\n",
    "\n",
    "    mean_mae_out_range = np.mean(diffOutRange)\n",
    "    mean_mre_out_range = np.mean(reldiffOutRange)\n",
    "    MAEoutRange_list.append(mean_mae_out_range)\n",
    "    MREoutRange_list.append(mean_mre_out_range)\n",
    "\n",
    "    # --- Long-Range Metrics ---\n",
    "    diffLongRange = np.abs(long_y_test - current_preds_long_range.flatten())\n",
    "    mean_mae_long_range = np.mean(diffLongRange)\n",
    "    MAElongRange_list.append(mean_mae_long_range)\n",
    "    \n",
    "    # --- Benchmark Calculation ---\n",
    "    # This part replicates the specific slicing and filtering from the notebook for the benchmark score\n",
    "    \n",
    "    # Specific filter for out-of-range benchmark calculation (from cell 11)\n",
    "    placeholder = absSum(outsideExpr)\n",
    "    indices_with_placeholder_22 = [i for i, val in enumerate(placeholder) if val == 22]\n",
    "    diffOutRange_for_benchmark_run = []\n",
    "    for idx in indices_with_placeholder_22:\n",
    "        diffOutRange_for_benchmark_run.append(np.abs(out_y_test[idx] - current_preds_out_range[idx]))\n",
    "    \n",
    "    meanDiff_OutRange_for_benchmark = np.mean(diffOutRange_for_benchmark_run)\n",
    "\n",
    "    # Specific slice for long-range benchmark calculation (from cell 13)\n",
    "    diffLongRange_for_benchmark_run = []\n",
    "    for j in range(200, 300):\n",
    "         diffLongRange_for_benchmark_run.append(np.abs(long_y_test[j] - current_preds_long_range[j]))\n",
    "\n",
    "    meanDiff_LongRange_for_benchmark = np.mean(diffLongRange_for_benchmark_run)\n",
    "\n",
    "    # Calculate the benchmark score for the current run\n",
    "    benchmark = 0\n",
    "    benchmark += baseline_deviation / (mean_mae_in_range**2) / 4\n",
    "    benchmark += baseline_out_deviation / (meanDiff_OutRange_for_benchmark**2) / 4\n",
    "    benchmark += baseline_long_deviation / (meanDiff_LongRange_for_benchmark**2) / 4\n",
    "    benchmark += baseline_relError / (mean_mre_out_range**2) / 4 # Using the overall MRE for out-of-range\n",
    "    benchmarks_list.append(benchmark)\n",
    "\n",
    "# --- Statistical Analysis and Final Output ---\n",
    "\n",
    "# Perform one-sample t-test against a population mean of 1.\n",
    "# Note: A t-test is only meaningful if n_bootstrap > 1.\n",
    "if n_bootstrap > 1:\n",
    "    stats1, p_value1 = ttest_1samp(MAEinRange_list, popmean=1)\n",
    "    stats2, p_value2 = ttest_1samp(MREinRange_list, popmean=1)\n",
    "    stats3, p_value3 = ttest_1samp(MAEoutRange_list, popmean=1)\n",
    "    stats4, p_value4 = ttest_1samp(MREoutRange_list, popmean=1)\n",
    "    stats5, p_value5 = ttest_1samp(MAElongRange_list, popmean=1)\n",
    "    stats6, p_value6 = ttest_1samp(benchmarks_list, popmean=1)\n",
    "\n",
    "    print(f\"MAE in Range P-value: {p_value1}\")\n",
    "    print(f\"MRE in Range P-value: {p_value2}\")\n",
    "    print(f\"MAE out Range P-value: {p_value3}\")\n",
    "    print(f\"MRE out Range P-value: {p_value4}\")\n",
    "    print(f\"MAE long Range P-value: {p_value5}\")\n",
    "    print(f\"Benchmark P-value: {p_value6}\\n\")\n",
    "else:\n",
    "    print(\"Cannot calculate p-values with n_bootstrap=1. Run more bootstraps for statistical tests.\\n\")\n",
    "\n",
    "\n",
    "# Print average metrics across all runs\n",
    "print(f\"Average MAE in Range: {np.mean(MAEinRange_list)}\")\n",
    "print(f\"Average MRE in Range: {np.mean(MREinRange_list)}\")\n",
    "print(f\"Average MAE out Range: {np.mean(MAEoutRange_list)}\")\n",
    "print(f\"Average MRE out Range: {np.mean(MREoutRange_list)}\")\n",
    "print(f\"Average MAE long Range: {np.mean(MAElongRange_list)}\")\n",
    "print(f\"Average benchmark: {np.mean(benchmarks_list)}\\n\")\n",
    "\n",
    "# Print the lists of metrics for inspection\n",
    "print(f\"MAE in Range List: {MAEinRange_list}\")\n",
    "print(f\"MRE in Range List: {MREinRange_list}\")\n",
    "print(f\"MAE out Range List: {MAEoutRange_list}\")\n",
    "print(f\"MRE out Range List: {MREoutRange_list}\")\n",
    "print(f\"MAE long Range List: {MAElongRange_list}\")\n",
    "print(f\"Benchmark List: {benchmarks_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4af7-38d6-42a7-829b-83ee1ffcc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old versions and stuff (TF GPU)",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
