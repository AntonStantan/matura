{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb54de36-1c17-4e1f-a8b8-06c388771c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 00:08:42.474527: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.525073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.525263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.527234: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.527362: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.527452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.637386: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.637634: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.637685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-08 00:08:42.637784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 00:08:42.637885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2919 MB memory:  -> device: 0, name: Orin, pci bus id: 0000:00:00.0, compute capability: 8.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762556926.356970  123970 service.cc:145] XLA service 0xfffe480043e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762556926.357090  123970 service.cc:153]   StreamExecutor device (0): Orin, Compute Capability 8.7\n",
      "2025-11-08 00:08:46.445592: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-08 00:08:46.697459: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 25.5589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762556927.289169  123970 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 21.9240 - val_loss: 18.1321\n",
      "Epoch 2/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.0075 - val_loss: 16.1136\n",
      "Epoch 3/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.4635 - val_loss: 14.8240\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.9160 - val_loss: 12.9423\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8636 - val_loss: 10.5709\n",
      "Epoch 6/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3808 - val_loss: 7.8885\n",
      "Epoch 7/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6266 - val_loss: 5.0932\n",
      "Epoch 8/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9907 - val_loss: 2.7554\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.0895 - val_loss: 1.4143\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1409 - val_loss: 0.8743\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7501 - val_loss: 0.6267\n",
      "Epoch 12/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5579 - val_loss: 0.4924\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4479 - val_loss: 0.4028\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3743 - val_loss: 0.3385\n",
      "Epoch 15/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3209 - val_loss: 0.2916\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2775 - val_loss: 0.2527\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2420 - val_loss: 0.2213\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2128 - val_loss: 0.1957\n",
      "Epoch 19/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1895 - val_loss: 0.1740\n",
      "Epoch 20/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1690 - val_loss: 0.1549\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1514 - val_loss: 0.1391\n",
      "Epoch 22/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1367 - val_loss: 0.1252\n",
      "Epoch 23/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1234 - val_loss: 0.1129\n",
      "Epoch 24/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1112 - val_loss: 0.1024\n",
      "Epoch 25/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1004 - val_loss: 0.0929\n",
      "Epoch 26/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0911 - val_loss: 0.0852\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0828 - val_loss: 0.0783\n",
      "Epoch 28/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0758 - val_loss: 0.0726\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0698 - val_loss: 0.0675\n",
      "Epoch 30/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0647 - val_loss: 0.0630\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0588\n",
      "Epoch 32/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0557 - val_loss: 0.0552\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0520 - val_loss: 0.0515\n",
      "Epoch 34/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0484 - val_loss: 0.0485\n",
      "Epoch 35/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0453 - val_loss: 0.0460\n",
      "Epoch 36/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0426 - val_loss: 0.0435\n",
      "Epoch 37/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0416\n",
      "Epoch 38/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0380 - val_loss: 0.0397\n",
      "Epoch 39/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0361 - val_loss: 0.0381\n",
      "Epoch 40/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0344 - val_loss: 0.0364\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.0349\n",
      "Epoch 42/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0336\n",
      "Epoch 43/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0298 - val_loss: 0.0326\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0315\n",
      "Epoch 45/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0271 - val_loss: 0.0303\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0258 - val_loss: 0.0293\n",
      "Epoch 47/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0283\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0273\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0226 - val_loss: 0.0264\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0256\n",
      "Epoch 51/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0249\n",
      "Epoch 52/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0242\n",
      "Epoch 53/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0195 - val_loss: 0.0235\n",
      "Epoch 54/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0229\n",
      "Epoch 55/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0225\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0179 - val_loss: 0.0221\n",
      "Epoch 57/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0218\n",
      "Epoch 58/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0216\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0170 - val_loss: 0.0215\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0166 - val_loss: 0.0213\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0212\n",
      "Epoch 63/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0160 - val_loss: 0.0211\n",
      "Epoch 65/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0158 - val_loss: 0.0209\n",
      "Epoch 66/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - val_loss: 0.0206\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0151 - val_loss: 0.0207\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0149 - val_loss: 0.0207\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - val_loss: 0.0210\n",
      "Epoch 70/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - val_loss: 0.0209\n",
      "Epoch 71/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0143 - val_loss: 0.0209\n",
      "Epoch 72/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0207\n",
      "Epoch 73/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0206\n",
      "Epoch 74/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - val_loss: 0.0203\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0134 - val_loss: 0.0200\n",
      "Epoch 76/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - val_loss: 0.0198\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - val_loss: 0.0195\n",
      "Epoch 78/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - val_loss: 0.0195\n",
      "Epoch 79/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0191\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - val_loss: 0.0188\n",
      "Epoch 81/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - val_loss: 0.0185\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0180\n",
      "Epoch 83/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - val_loss: 0.0177\n",
      "Epoch 84/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0112 - val_loss: 0.0175\n",
      "Epoch 85/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0110 - val_loss: 0.0174\n",
      "Epoch 86/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0108 - val_loss: 0.0177\n",
      "Epoch 87/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0178\n",
      "Epoch 88/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0105 - val_loss: 0.0174\n",
      "Epoch 89/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0173\n",
      "Epoch 90/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0174\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 92/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0100 - val_loss: 0.0171\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0171\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0170\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0168\n",
      "Epoch 96/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0167\n",
      "Epoch 97/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0166\n",
      "Epoch 98/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0168\n",
      "Epoch 99/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0159\n",
      "Epoch 100/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0160\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0160\n",
      "Epoch 102/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 103/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0156\n",
      "Epoch 104/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0160\n",
      "Epoch 105/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0156\n",
      "Epoch 106/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 107/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0154\n",
      "Epoch 108/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0153\n",
      "Epoch 109/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0155\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0152\n",
      "Epoch 111/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0152\n",
      "Epoch 112/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0150\n",
      "Epoch 113/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0150\n",
      "Epoch 114/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0152\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0151\n",
      "Epoch 116/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "Epoch 117/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0148\n",
      "Epoch 118/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0145\n",
      "Epoch 119/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0143\n",
      "Epoch 120/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0144\n",
      "Epoch 121/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0141\n",
      "Epoch 122/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 123/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0068 - val_loss: 0.0133\n",
      "Epoch 124/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0131\n",
      "Epoch 125/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0065 - val_loss: 0.0132\n",
      "Epoch 126/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0126\n",
      "Epoch 127/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0061 - val_loss: 0.0124\n",
      "Epoch 128/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0119\n",
      "Epoch 129/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0059 - val_loss: 0.0117\n",
      "Epoch 130/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0112\n",
      "Epoch 131/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0056 - val_loss: 0.0109\n",
      "Epoch 132/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0107\n",
      "Epoch 133/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 134/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 135/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0102\n",
      "Epoch 136/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0098\n",
      "Epoch 137/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0050 - val_loss: 0.0097\n",
      "Epoch 138/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 139/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0093\n",
      "Epoch 140/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0089\n",
      "Epoch 141/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0048 - val_loss: 0.0086\n",
      "Epoch 142/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 143/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0083\n",
      "Epoch 144/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0078\n",
      "Epoch 145/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0046 - val_loss: 0.0077\n",
      "Epoch 146/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0076\n",
      "Epoch 147/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 148/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 149/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0073\n",
      "Epoch 150/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0047 - val_loss: 0.0072\n",
      "Epoch 151/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 152/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 153/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 154/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 155/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 156/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 157/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 158/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 159/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0042 - val_loss: 0.0068\n",
      "Epoch 160/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 161/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 162/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 163/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 164/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 165/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 166/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 167/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 168/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 169/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 170/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 171/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 172/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 173/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 174/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 175/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 176/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 177/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 178/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 179/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 180/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 181/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 182/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 183/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 184/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 19.1644 - val_loss: 16.1755\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.4964 - val_loss: 15.1603\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.2966 - val_loss: 13.9914\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8573 - val_loss: 12.3012\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8196 - val_loss: 9.8223\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0259 - val_loss: 6.5654\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8743 - val_loss: 3.3763\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.4905 - val_loss: 1.5873\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4025 - val_loss: 1.0195\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0249 - val_loss: 0.8220\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8333 - val_loss: 0.7015\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7093 - val_loss: 0.6156\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6098 - val_loss: 0.5335\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5179 - val_loss: 0.4530\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4367 - val_loss: 0.3912\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3729 - val_loss: 0.3413\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3205 - val_loss: 0.3011\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2790 - val_loss: 0.2670\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2456 - val_loss: 0.2381\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2176 - val_loss: 0.2143\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1940 - val_loss: 0.1940\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1726 - val_loss: 0.1763\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1545 - val_loss: 0.1606\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1390 - val_loss: 0.1474\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1263 - val_loss: 0.1354\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1148 - val_loss: 0.1242\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1048 - val_loss: 0.1143\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0958 - val_loss: 0.1059\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0878 - val_loss: 0.0977\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0806 - val_loss: 0.0911\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0744 - val_loss: 0.0853\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0692 - val_loss: 0.0804\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0646 - val_loss: 0.0764\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0607 - val_loss: 0.0725\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0573 - val_loss: 0.0686\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0543 - val_loss: 0.0652\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0515 - val_loss: 0.0621\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.0590\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0464 - val_loss: 0.0571\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0443 - val_loss: 0.0549\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0423 - val_loss: 0.0527\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0404 - val_loss: 0.0507\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0386 - val_loss: 0.0491\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0369 - val_loss: 0.0474\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0354 - val_loss: 0.0458\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0340 - val_loss: 0.0446\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.0439\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.0428\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.0420\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capybara/Desktop/matura_project_python/github/matura/FNN1_1.py:246: RuntimeWarning: divide by zero encountered in divide\n",
      "  relativeError = np.where(np.array(y_test) != 0, deviation.flatten() / np.abs(np.array(y_test)), deviation.flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here they are: 0.031258426732425425, 12.726464755918206, 17.562249522446056, 0.04474203202058679\n",
      "-1 + -5 + -4\n",
      "2543\n",
      "-10.0\n",
      "\n",
      "Expressions not in x:\n",
      "2 - 4 + -5\n",
      "True\n",
      "1457\n",
      "-7.0\n",
      "15\n",
      "-4.0\n",
      "[-5.   1.   1.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"g4gLSTM.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation\n",
    "print(f\"Here they are: {baseline_deviation}, {baseline_out_deviation}, {baseline_long_deviation}, {baseline_relError}\")\n",
    "# Now you can import from GetXY.py\n",
    "from GetXY import x_train, y_train, x_val, y_val, x_test, y_test, out_x_test, out_y_test, long_x_test, long_y_test, outsideExpr, absSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5505dc-debc-4d51-8707-9f9dcf8c4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable weights for attention mechanism\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        self.u = self.add_weight(name=\"att_u\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Score computation\n",
    "        v = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        vu = tf.tensordot(v, self.u, axes=1)\n",
    "        alphas = tf.nn.softmax(vu)\n",
    "\n",
    "        # Weighted sum of input\n",
    "        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), axis=1)\n",
    "        return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5ddb3e-fff3-403e-9e7a-e90272a0e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_attention_model(input_shape, lstm_units):\n",
    "    inputs = keras.Input(shape=(input_shape, 1))\n",
    "    \n",
    "    # Bi-LSTM layer\n",
    "    lstm_out = keras.layers.LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    \n",
    "    # Add Attention layer\n",
    "    attention_out, attention_weights = AttentionLayer()(lstm_out)\n",
    "    \n",
    "    # Final Dense layer\n",
    "    outputs = keras.layers.Dense(1, activation=\"linear\")(attention_out)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbc8430-b852-4a70-a749-d78624992bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 1\n",
    "min_neurons = 35\n",
    "max_neurons = 35\n",
    "neuron_step = 1\n",
    "min_layers = 2\n",
    "max_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288ccf6f-f2de-4d87-9196-41ba8d4b8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b265713e-faf5-4621-958b-858653756e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True,\n",
    "    monitor='mse',\n",
    "    mode = \"min\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73eb958-830a-4a1e-a87e-e81a0754f060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "bootstrap_predsInRange = []\n",
    "bootstrap_predsOutRange = []\n",
    "bootstrap_predsLongRange = []\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            sample_indices = np.random.choice(len(x_train), size=len(x_train), replace=True)\n",
    "            x_train_bootstrap = x_train[sample_indices]\n",
    "            y_train_bootstrap = np.array(y_train)[sample_indices]\n",
    "            bootstrap_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_bootstrap, y_train_bootstrap)).batch(32)\n",
    "\n",
    "            #bootstrap_model = build_model(len(x_train[0]), l, n)\n",
    "            bootstrap_model = build_lstm_attention_model(len(x_train[0]),n)\n",
    "\n",
    "            bootstrap_model.compile(optimizer = \"adam\", loss = \"mse\", metrics=['mse'])\n",
    "            \n",
    "            bootstrap_model.fit(\n",
    "            bootstrap_train_dataset,\n",
    "            epochs=100,\n",
    "            verbose=0, # Suppress output\n",
    "            callbacks=[early_stopping]\n",
    "            )\n",
    "\n",
    "            bootstrap_predsInRange.append(bootstrap_model.predict(x_test))\n",
    "            bootstrap_predsOutRange.append(bootstrap_model.predict(out_x_test))\n",
    "            bootstrap_predsLongRange.append(bootstrap_model.predict(long_x_test))\n",
    "\n",
    "bootstrap_predsInRange = np.array(bootstrap_predsInRange)\n",
    "bootstrap_predsOutRange = np.array(bootstrap_predsOutRange)\n",
    "\n",
    "bootstrap_predsLongRange = np.array(bootstrap_predsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d19a48-d6bc-4977-add8-4d6b8600dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,180</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,295</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m)         │         \u001b[38;5;34m5,180\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m1,295\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │ \u001b[38;5;34m15\u001b[0m)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,535</span> (76.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,535\u001b[0m (76.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,511</span> (25.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,511\u001b[0m (25.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,024</span> (50.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m13,024\u001b[0m (50.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bootstrap_predsInRange.shape\n",
    "bootstrap_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbff871c-ce79-42e9-9c59-4e0a3978c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = int(bootstrap_predsInRange.shape[0]/n_bootstrap)\n",
    "mean_modelpredsInRange = []\n",
    "mean_modelpredsOutRange = []\n",
    "mean_modelpredsLongRange = []\n",
    "\n",
    "for model_index in range(num_models):\n",
    "    model_predsInRange = bootstrap_predsInRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsOutRange = bootstrap_predsOutRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsLongRange = bootstrap_predsLongRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "\n",
    "    mean_modelpredsInRange.append(np.mean(model_predsInRange, axis = 0))\n",
    "    mean_modelpredsOutRange.append(np.mean(model_predsOutRange, axis = 0))\n",
    "    mean_modelpredsLongRange.append(np.mean(model_predsLongRange, axis = 0))\n",
    "\n",
    "mean_modelpredsInRange = np.array(mean_modelpredsInRange)\n",
    "mean_modelpredsOutRange = np.array(mean_modelpredsOutRange)\n",
    "mean_modelpredsLongRange = np.array(mean_modelpredsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5caaef0-51a6-47c4-8271-f997cc61cee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.41754225], dtype=float32)]\n",
      "[array([0.17438732], dtype=float32)]\n",
      "[array([2.8197246], dtype=float32)]\n",
      "[array([0.28262615], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "mean_modelpredsInRange.shape\n",
    "diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  diff_differences.append(calc/len(y_test))\n",
    "print(diff_differences)\n",
    "\n",
    "rel_diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] != 0:\n",
    "        calc += (abs(y_test[i]-mean_modelpredsInRange[j][i])/abs(y_test[i]))\n",
    "    else:\n",
    "        calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  rel_diff_differences.append(calc/len(y_test))\n",
    "print(rel_diff_differences)\n",
    "\n",
    "out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  out_diff_differences.append(calc/len(out_y_test))\n",
    "print(out_diff_differences)\n",
    "\n",
    "rel_out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    if out_y_test[i] != 0:\n",
    "        calc += (abs(out_y_test[i]-mean_modelpredsOutRange[j][i])/abs(out_y_test[i]))\n",
    "    else:\n",
    "        calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  rel_out_diff_differences.append(calc/len(out_y_test))\n",
    "print(rel_out_diff_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9ea613-d3b6-4ba5-9c40-4c1adfe35b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = absSum(outsideExpr)\n",
    "diff_out_differences = []\n",
    "indices_with_placeholder_22 = [i for i, val in enumerate(placeholder) if val == 22] \n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in indices_with_placeholder_22:\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  diff_out_differences.append(calc/len(indices_with_placeholder_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbfc7ff5-3b4f-43ad-9624-7a1b4922b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_out_relError = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(mean_modelpredsOutRange.shape[1]):\n",
    "    calc += abs((out_y_test[i]-mean_modelpredsOutRange[j][i])/out_y_test[i])\n",
    "  diff_out_relError.append(calc/mean_modelpredsOutRange.shape[1])\n",
    "\n",
    "\n",
    "y_test_safe = np.copy(y_test).astype(float) # Ensure float type for division\n",
    "y_test_safe[y_test_safe == 0] = 1\n",
    "diff_relError = np.array(diff_differences) / np.array(y_test_safe)\n",
    "\n",
    "diff_relErrors = (np.array(diff_out_relError) + np.array(diff_relError))/2.0\n",
    "diff_avRelError = np.mean(diff_relErrors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa09f391-1813-455c-bc3a-a1c77ba40962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.6574671], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(200,300):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  diff_long_differences.append(calc/100)\n",
    "\n",
    "meow_diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(long_y_test)):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  meow_diff_long_differences.append(calc/len(long_y_test))\n",
    "print(meow_diff_long_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b9ddb7-dc63-4149-b9f4-65df7911f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(diff_differences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e4c869e-4aaf-4eac-ad70-fc06484bd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"transformer0.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b244564-e6f9-4c80-b1f1-75cdcbbddffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.8864486], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "for i in range(len(diff_differences)):\n",
    "  calc = 0\n",
    "  calc += baseline_deviation / (diff_differences[i]**2)\n",
    "  calc += baseline_out_deviation / (diff_out_differences[i]**2)\n",
    "  calc += baseline_long_deviation / (diff_long_differences[i]**2)\n",
    "  calc += baseline_relError / (diff_avRelError[i]**2)\n",
    "  benchmark.append(calc/4)\n",
    "print(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "727be262-7945-429c-adf4-b955b9ae5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = (max_neurons - min_neurons) // neuron_step + 1\n",
    "num_layers = max_layers - min_layers + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f33ee47-656c-401e-9e78-ec7a84f66f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new array to include the means\n",
    "# Add a column for row means and a row for column means (and a corner for the overall mean)\n",
    "benchmark_array = np.array(benchmark).reshape(num_layers, num_neurons)\n",
    "extended_benchmark_array = np.zeros((num_layers + 1, num_neurons + 1))\n",
    "\n",
    "Neurons_means = np.mean(benchmark_array, axis=0)\n",
    "Layers_means = np.mean(benchmark_array, axis=1)\n",
    "\n",
    "# Copy the original benchmark data\n",
    "extended_benchmark_array[:num_layers, :num_neurons] = benchmark_array\n",
    "\n",
    "# Add the row means\n",
    "extended_benchmark_array[:num_layers, num_neurons] = Layers_means\n",
    "\n",
    "# Add the column means\n",
    "extended_benchmark_array[num_layers, :num_neurons] = Neurons_means\n",
    "\n",
    "# Calculate and add the overall mean\n",
    "overall_mean = np.mean(benchmark_array)\n",
    "extended_benchmark_array[num_layers, num_neurons] = overall_mean\n",
    "\n",
    "\n",
    "# Create updated tick labels for the heatmap\n",
    "xticklabels_extended = list(np.arange(min_neurons, max_neurons + 1, neuron_step)) + ['Row Mean']\n",
    "yticklabels_extended = list(np.arange(min_layers, max_layers + 1)) + ['Column Mean']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10)) # Adjust figure size for the extra row/column\n",
    "ax = sns.heatmap(extended_benchmark_array, annot=True, fmt=\".2f\", cmap=\"inferno\",\n",
    "            xticklabels=xticklabels_extended,\n",
    "            yticklabels=yticklabels_extended)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.hlines(y=6, xmin=xmin, xmax=xmax, colors='lightblue', lw=2, linestyle='-')\n",
    "ax.vlines(x=11, ymin=ymin, ymax=ymax, colors='lightblue', lw=2, linestyle='-')\n",
    "plt.ylabel('Number of Layers')\n",
    "plt.xlabel('Number of Neurons per Layer')\n",
    "plt.title('Heatmap of the Benchmarks with Row and Column Means')\n",
    "plt.savefig(\"bigHeatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2678ff-6aa5-44db-aae0-90cf9c8a16c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4af7-38d6-42a7-829b-83ee1ffcc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old versions and stuff (TF GPU)",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
