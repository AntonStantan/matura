{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb54de36-1c17-4e1f-a8b8-06c388771c57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 17:56:29.248558: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.647405: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.647712: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.650896: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.651160: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.651357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.793940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.794383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.794472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-11-08 17:56:35.794676: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-08 17:56:35.794847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3414 MB memory:  -> device: 0, name: Orin, pci bus id: 0000:00:00.0, compute capability: 8.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762621007.873994    4610 service.cc:145] XLA service 0xfffe58003580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762621007.874082    4610 service.cc:153]   StreamExecutor device (0): Orin, Compute Capability 8.7\n",
      "2025-11-08 17:56:48.099552: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-08 17:56:48.522443: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/60\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 27.8114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762621011.377397    4610 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 23.0747 - val_loss: 17.4281\n",
      "Epoch 2/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 17.3115 - val_loss: 15.8435\n",
      "Epoch 3/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.2569 - val_loss: 14.9728\n",
      "Epoch 4/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 15.2498 - val_loss: 13.8306\n",
      "Epoch 5/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.8542 - val_loss: 12.3045\n",
      "Epoch 6/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.0304 - val_loss: 10.3232\n",
      "Epoch 7/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7449 - val_loss: 8.0317\n",
      "Epoch 8/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1800 - val_loss: 5.6481\n",
      "Epoch 9/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.6850 - val_loss: 3.4891\n",
      "Epoch 10/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6704 - val_loss: 1.9155\n",
      "Epoch 11/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4610 - val_loss: 1.1739\n",
      "Epoch 12/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9812 - val_loss: 0.8932\n",
      "Epoch 13/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7768 - val_loss: 0.7375\n",
      "Epoch 14/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6421 - val_loss: 0.6206\n",
      "Epoch 15/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5418 - val_loss: 0.5305\n",
      "Epoch 16/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4661 - val_loss: 0.4643\n",
      "Epoch 17/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4090 - val_loss: 0.4087\n",
      "Epoch 18/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3623 - val_loss: 0.3618\n",
      "Epoch 19/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3240 - val_loss: 0.3227\n",
      "Epoch 20/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2915 - val_loss: 0.2911\n",
      "Epoch 21/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2633 - val_loss: 0.2646\n",
      "Epoch 22/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2397 - val_loss: 0.2427\n",
      "Epoch 23/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2202 - val_loss: 0.2240\n",
      "Epoch 24/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2026 - val_loss: 0.2070\n",
      "Epoch 25/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1873 - val_loss: 0.1906\n",
      "Epoch 26/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1734 - val_loss: 0.1767\n",
      "Epoch 27/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1614 - val_loss: 0.1646\n",
      "Epoch 28/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1512 - val_loss: 0.1542\n",
      "Epoch 29/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1405 - val_loss: 0.1443\n",
      "Epoch 30/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1311 - val_loss: 0.1350\n",
      "Epoch 31/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1218 - val_loss: 0.1274\n",
      "Epoch 32/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1138 - val_loss: 0.1200\n",
      "Epoch 33/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1067 - val_loss: 0.1126\n",
      "Epoch 34/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0996 - val_loss: 0.1056\n",
      "Epoch 35/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0933 - val_loss: 0.1003\n",
      "Epoch 36/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0875 - val_loss: 0.0954\n",
      "Epoch 37/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0817 - val_loss: 0.0899\n",
      "Epoch 38/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0764 - val_loss: 0.0850\n",
      "Epoch 39/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0713 - val_loss: 0.0800\n",
      "Epoch 40/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0663 - val_loss: 0.0747\n",
      "Epoch 41/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0619 - val_loss: 0.0693\n",
      "Epoch 42/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0581 - val_loss: 0.0652\n",
      "Epoch 43/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0549 - val_loss: 0.0617\n",
      "Epoch 44/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0520 - val_loss: 0.0585\n",
      "Epoch 45/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0495 - val_loss: 0.0556\n",
      "Epoch 46/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0474 - val_loss: 0.0531\n",
      "Epoch 47/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0454 - val_loss: 0.0506\n",
      "Epoch 48/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0439 - val_loss: 0.0485\n",
      "Epoch 49/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0425 - val_loss: 0.0470\n",
      "Epoch 50/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0413 - val_loss: 0.0455\n",
      "Epoch 51/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0402 - val_loss: 0.0443\n",
      "Epoch 52/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0429\n",
      "Epoch 53/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0380 - val_loss: 0.0416\n",
      "Epoch 54/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0370 - val_loss: 0.0407\n",
      "Epoch 55/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0396\n",
      "Epoch 56/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0385\n",
      "Epoch 57/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.0379\n",
      "Epoch 58/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.0371\n",
      "Epoch 59/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0310 - val_loss: 0.0363\n",
      "Epoch 60/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.0354\n",
      "Epoch 61/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0343\n",
      "Epoch 62/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0333\n",
      "Epoch 63/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0324\n",
      "Epoch 64/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0313\n",
      "Epoch 65/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.0302\n",
      "Epoch 66/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0291\n",
      "Epoch 67/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0282\n",
      "Epoch 68/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0274\n",
      "Epoch 69/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0238 - val_loss: 0.0266\n",
      "Epoch 70/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0258\n",
      "Epoch 71/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0249\n",
      "Epoch 72/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0241\n",
      "Epoch 73/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0223 - val_loss: 0.0236\n",
      "Epoch 74/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0220 - val_loss: 0.0229\n",
      "Epoch 75/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0224\n",
      "Epoch 76/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0213 - val_loss: 0.0219\n",
      "Epoch 77/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0208 - val_loss: 0.0214\n",
      "Epoch 78/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0209\n",
      "Epoch 79/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0206\n",
      "Epoch 80/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0201\n",
      "Epoch 81/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0197\n",
      "Epoch 82/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0195\n",
      "Epoch 83/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0191\n",
      "Epoch 84/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0188\n",
      "Epoch 85/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 86/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0172 - val_loss: 0.0184\n",
      "Epoch 87/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0169 - val_loss: 0.0182\n",
      "Epoch 88/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0167 - val_loss: 0.0180\n",
      "Epoch 89/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0177\n",
      "Epoch 90/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0177\n",
      "Epoch 91/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0175\n",
      "Epoch 92/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 93/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - val_loss: 0.0170\n",
      "Epoch 94/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0152 - val_loss: 0.0168\n",
      "Epoch 95/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0149 - val_loss: 0.0167\n",
      "Epoch 96/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0145 - val_loss: 0.0168\n",
      "Epoch 97/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 98/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0164\n",
      "Epoch 99/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 100/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - val_loss: 0.0159\n",
      "Epoch 101/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0156\n",
      "Epoch 102/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0128 - val_loss: 0.0152\n",
      "Epoch 103/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - val_loss: 0.0150\n",
      "Epoch 104/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - val_loss: 0.0147\n",
      "Epoch 105/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 106/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - val_loss: 0.0142\n",
      "Epoch 107/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 108/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0116 - val_loss: 0.0137\n",
      "Epoch 109/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - val_loss: 0.0135\n",
      "Epoch 110/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0113 - val_loss: 0.0132\n",
      "Epoch 111/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 112/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0109 - val_loss: 0.0129\n",
      "Epoch 113/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 114/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 115/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 116/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 117/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 118/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0117\n",
      "Epoch 119/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 120/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 121/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0110\n",
      "Epoch 122/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 123/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 124/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 125/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 126/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 127/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0105\n",
      "Epoch 128/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 129/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0101\n",
      "Epoch 130/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0099\n",
      "Epoch 131/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 132/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0097\n",
      "Epoch 133/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 134/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 135/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 136/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 137/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 138/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 139/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 140/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0074 - val_loss: 0.0087\n",
      "Epoch 141/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0073 - val_loss: 0.0085\n",
      "Epoch 142/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 143/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0072 - val_loss: 0.0083\n",
      "Epoch 144/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 145/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0070 - val_loss: 0.0080\n",
      "Epoch 146/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 147/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0067 - val_loss: 0.0077\n",
      "Epoch 148/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 149/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0066 - val_loss: 0.0076\n",
      "Epoch 150/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 151/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 152/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0062 - val_loss: 0.0073\n",
      "Epoch 153/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 154/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 155/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 156/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 157/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0059 - val_loss: 0.0070\n",
      "Epoch 158/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0058 - val_loss: 0.0069\n",
      "Epoch 159/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 160/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 161/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 162/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 163/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0067\n",
      "Epoch 164/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 165/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 166/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 167/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 168/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 169/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 170/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 171/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 172/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 173/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 174/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 175/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 176/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 177/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 178/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0052 - val_loss: 0.0066\n",
      "Epoch 179/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 180/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 181/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 182/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 183/200\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0053 - val_loss: 0.0066\n",
      "Epoch 1/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 19.8147 - val_loss: 16.5943\n",
      "Epoch 2/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.6142 - val_loss: 15.5795\n",
      "Epoch 3/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.4285 - val_loss: 14.2933\n",
      "Epoch 4/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8925 - val_loss: 12.3860\n",
      "Epoch 5/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.7508 - val_loss: 9.7183\n",
      "Epoch 6/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8063 - val_loss: 6.3449\n",
      "Epoch 7/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4.5442 - val_loss: 3.3540\n",
      "Epoch 8/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1827 - val_loss: 1.6606\n",
      "Epoch 9/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1907 - val_loss: 1.1134\n",
      "Epoch 10/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8864 - val_loss: 0.9089\n",
      "Epoch 11/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7315 - val_loss: 0.7706\n",
      "Epoch 12/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6186 - val_loss: 0.6633\n",
      "Epoch 13/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5350 - val_loss: 0.5771\n",
      "Epoch 14/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4667 - val_loss: 0.5105\n",
      "Epoch 15/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4131 - val_loss: 0.4567\n",
      "Epoch 16/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3695 - val_loss: 0.4084\n",
      "Epoch 17/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3321 - val_loss: 0.3734\n",
      "Epoch 18/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3010 - val_loss: 0.3472\n",
      "Epoch 19/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2757 - val_loss: 0.3242\n",
      "Epoch 20/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2532 - val_loss: 0.3014\n",
      "Epoch 21/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2329 - val_loss: 0.2807\n",
      "Epoch 22/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2142 - val_loss: 0.2608\n",
      "Epoch 23/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1964 - val_loss: 0.2429\n",
      "Epoch 24/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1797 - val_loss: 0.2241\n",
      "Epoch 25/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1652 - val_loss: 0.2067\n",
      "Epoch 26/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1517 - val_loss: 0.1918\n",
      "Epoch 27/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1395 - val_loss: 0.1763\n",
      "Epoch 28/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1279 - val_loss: 0.1632\n",
      "Epoch 29/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1180 - val_loss: 0.1514\n",
      "Epoch 30/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1089 - val_loss: 0.1404\n",
      "Epoch 31/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1008 - val_loss: 0.1304\n",
      "Epoch 32/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0939 - val_loss: 0.1222\n",
      "Epoch 33/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0875 - val_loss: 0.1151\n",
      "Epoch 34/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0818 - val_loss: 0.1089\n",
      "Epoch 35/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0769 - val_loss: 0.1029\n",
      "Epoch 36/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0728 - val_loss: 0.0979\n",
      "Epoch 37/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0691 - val_loss: 0.0923\n",
      "Epoch 38/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0655 - val_loss: 0.0882\n",
      "Epoch 39/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0624 - val_loss: 0.0841\n",
      "Epoch 40/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0801\n",
      "Epoch 41/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0570 - val_loss: 0.0771\n",
      "Epoch 42/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0549 - val_loss: 0.0742\n",
      "Epoch 43/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0531 - val_loss: 0.0723\n",
      "Epoch 44/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0516 - val_loss: 0.0704\n",
      "Epoch 45/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0504 - val_loss: 0.0687\n",
      "Epoch 46/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0493 - val_loss: 0.0669\n",
      "Epoch 47/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0483 - val_loss: 0.0655\n",
      "Epoch 48/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0473 - val_loss: 0.0648\n",
      "Epoch 49/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0465 - val_loss: 0.0639\n",
      "Epoch 50/50\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0458 - val_loss: 0.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capybara/Desktop/matura_project_python/github/matura/FNN1_1.py:246: RuntimeWarning: divide by zero encountered in divide\n",
      "  relativeError = np.where(np.array(y_test) != 0, deviation.flatten() / np.abs(np.array(y_test)), deviation.flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here they are: 0.03872913364563116, 11.27094316219686, 20.628133625018606, 0.041899602123372605\n",
      "2 - 1 + 4\n",
      "2543\n",
      "5.0\n",
      "\n",
      "Expressions not in x:\n",
      "-2 + -1 + 0\n",
      "True\n",
      "1457\n",
      "-3.0\n",
      "15\n",
      "-4.0\n",
      "[-5.   1.   1.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"g4gLSTM.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation\n",
    "print(f\"Here they are: {baseline_deviation}, {baseline_out_deviation}, {baseline_long_deviation}, {baseline_relError}\")\n",
    "# Now you can import from GetXY.py\n",
    "from GetXY import x_train, y_train, x_val, y_val, x_test, y_test, out_x_test, out_y_test, long_x_test, long_y_test, outsideExpr, absSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5505dc-debc-4d51-8707-9f9dcf8c4b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Trainable weights for attention mechanism\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        self.u = self.add_weight(name=\"att_u\", shape=(input_shape[-1],),\n",
    "                                 initializer=\"glorot_uniform\", trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Score computation\n",
    "        v = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
    "        vu = tf.tensordot(v, self.u, axes=1)\n",
    "        alphas = tf.nn.softmax(vu)\n",
    "\n",
    "        # Weighted sum of input\n",
    "        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), axis=1)\n",
    "        return output, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5ddb3e-fff3-403e-9e7a-e90272a0e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_attention_model(input_shape, lstm_units):\n",
    "    inputs = keras.Input(shape=(input_shape, 1))\n",
    "    \n",
    "    # Bi-LSTM layer\n",
    "    lstm_out = keras.layers.LSTM(lstm_units, return_sequences=True)(inputs)\n",
    "    \n",
    "    # Add Attention layer\n",
    "    attention_out, attention_weights = AttentionLayer()(lstm_out)\n",
    "    \n",
    "    # Final Dense layer\n",
    "    outputs = keras.layers.Dense(1, activation=\"linear\")(attention_out)\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbc8430-b852-4a70-a749-d78624992bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bootstrap = 5\n",
    "min_neurons = 35\n",
    "max_neurons = 35\n",
    "neuron_step = 1\n",
    "min_layers = 2\n",
    "max_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288ccf6f-f2de-4d87-9196-41ba8d4b8534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            count += 1\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73eb958-830a-4a1e-a87e-e81a0754f060",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capybara/Desktop/matura_project_python/tf_env/lib/python3.10/site-packages/keras/src/callbacks/early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "bootstrap_predsInRange = []\n",
    "bootstrap_predsOutRange = []\n",
    "bootstrap_predsLongRange = []\n",
    "for n in range(min_neurons, max_neurons+1, neuron_step):\n",
    "    for l in range(min_layers, max_layers+1):\n",
    "        for b in range(n_bootstrap):\n",
    "            early_stopping = keras.callbacks.EarlyStopping(\n",
    "                patience=10,\n",
    "                min_delta=0.0001,\n",
    "                restore_best_weights=True,\n",
    "                monitor='val_loss',\n",
    "                mode = \"min\"\n",
    "            )           \n",
    "            sample_indices = np.random.choice(len(x_train), size=len(x_train), replace=True)\n",
    "            x_train_bootstrap = x_train[sample_indices]\n",
    "            y_train_bootstrap = np.array(y_train)[sample_indices]\n",
    "            bootstrap_train_dataset = tf.data.Dataset.from_tensor_slices((x_train_bootstrap, y_train_bootstrap)).batch(32)\n",
    "\n",
    "            #bootstrap_model = build_model(len(x_train[0]), l, n)\n",
    "            bootstrap_model = build_lstm_attention_model(len(x_train[0]),n)\n",
    "\n",
    "            bootstrap_model.compile(optimizer = \"adam\", loss = \"mse\", metrics=['mse'])\n",
    "            \n",
    "            bootstrap_model.fit(\n",
    "            bootstrap_train_dataset,\n",
    "            epochs=100,\n",
    "            verbose=0, # Suppress output\n",
    "            callbacks=[early_stopping]\n",
    "            )\n",
    "\n",
    "            bootstrap_predsInRange.append(bootstrap_model.predict(x_test))\n",
    "            bootstrap_predsOutRange.append(bootstrap_model.predict(out_x_test))\n",
    "            bootstrap_predsLongRange.append(bootstrap_model.predict(long_x_test))\n",
    "\n",
    "bootstrap_predsInRange = np.array(bootstrap_predsInRange)\n",
    "bootstrap_predsOutRange = np.array(bootstrap_predsOutRange)\n",
    "\n",
    "bootstrap_predsLongRange = np.array(bootstrap_predsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d19a48-d6bc-4977-add8-4d6b8600dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,180</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_4               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,295</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m35\u001b[0m)         │         \u001b[38;5;34m5,180\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer_4               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │         \u001b[38;5;34m1,295\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │ \u001b[38;5;34m15\u001b[0m)]                   │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,535</span> (76.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,535\u001b[0m (76.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,511</span> (25.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,511\u001b[0m (25.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,024</span> (50.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m13,024\u001b[0m (50.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bootstrap_predsInRange.shape\n",
    "bootstrap_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbff871c-ce79-42e9-9c59-4e0a3978c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = int(bootstrap_predsInRange.shape[0]/n_bootstrap)\n",
    "mean_modelpredsInRange = []\n",
    "mean_modelpredsOutRange = []\n",
    "mean_modelpredsLongRange = []\n",
    "\n",
    "for model_index in range(num_models):\n",
    "    model_predsInRange = bootstrap_predsInRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsOutRange = bootstrap_predsOutRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "    model_predsLongRange = bootstrap_predsLongRange[model_index*n_bootstrap : (model_index+1)*n_bootstrap]\n",
    "\n",
    "    mean_modelpredsInRange.append(np.mean(model_predsInRange, axis = 0))\n",
    "    mean_modelpredsOutRange.append(np.mean(model_predsOutRange, axis = 0))\n",
    "    mean_modelpredsLongRange.append(np.mean(model_predsLongRange, axis = 0))\n",
    "\n",
    "mean_modelpredsInRange = np.array(mean_modelpredsInRange)\n",
    "mean_modelpredsOutRange = np.array(mean_modelpredsOutRange)\n",
    "mean_modelpredsLongRange = np.array(mean_modelpredsLongRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5caaef0-51a6-47c4-8271-f997cc61cee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.62487334], dtype=float32)]\n",
      "[array([0.21764688], dtype=float32)]\n",
      "[array([3.6160257], dtype=float32)]\n",
      "[array([0.36689737], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "mean_modelpredsInRange.shape\n",
    "diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  diff_differences.append(calc/len(y_test))\n",
    "print(diff_differences)\n",
    "\n",
    "rel_diff_differences = []\n",
    "for j in range(mean_modelpredsInRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(y_test)):\n",
    "    if y_test[i] != 0:\n",
    "        calc += (abs(y_test[i]-mean_modelpredsInRange[j][i])/abs(y_test[i]))\n",
    "    else:\n",
    "        calc += abs(y_test[i]-mean_modelpredsInRange[j][i])\n",
    "  rel_diff_differences.append(calc/len(y_test))\n",
    "print(rel_diff_differences)\n",
    "\n",
    "out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  out_diff_differences.append(calc/len(out_y_test))\n",
    "print(out_diff_differences)\n",
    "\n",
    "rel_out_diff_differences = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(out_y_test)):\n",
    "    if out_y_test[i] != 0:\n",
    "        calc += (abs(out_y_test[i]-mean_modelpredsOutRange[j][i])/abs(out_y_test[i]))\n",
    "    else:\n",
    "        calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  rel_out_diff_differences.append(calc/len(out_y_test))\n",
    "print(rel_out_diff_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc9ea613-d3b6-4ba5-9c40-4c1adfe35b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = absSum(outsideExpr)\n",
    "diff_out_differences = []\n",
    "indices_with_placeholder_22 = [i for i, val in enumerate(placeholder) if val == 22] \n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in indices_with_placeholder_22:\n",
    "    calc += abs(out_y_test[i]-mean_modelpredsOutRange[j][i])\n",
    "  diff_out_differences.append(calc/len(indices_with_placeholder_22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbfc7ff5-3b4f-43ad-9624-7a1b4922b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_out_relError = []\n",
    "for j in range(mean_modelpredsOutRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(mean_modelpredsOutRange.shape[1]):\n",
    "    calc += abs((out_y_test[i]-mean_modelpredsOutRange[j][i])/out_y_test[i])\n",
    "  diff_out_relError.append(calc/mean_modelpredsOutRange.shape[1])\n",
    "\n",
    "\n",
    "y_test_safe = np.copy(y_test).astype(float) # Ensure float type for division\n",
    "y_test_safe[y_test_safe == 0] = 1\n",
    "diff_relError = np.array(diff_differences) / np.array(y_test_safe)\n",
    "\n",
    "diff_relErrors = (np.array(diff_out_relError) + np.array(diff_relError))/2.0\n",
    "diff_avRelError = np.mean(diff_relErrors, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa09f391-1813-455c-bc3a-a1c77ba40962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.6398141], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(200,300):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  diff_long_differences.append(calc/100)\n",
    "\n",
    "meow_diff_long_differences = []\n",
    "for j in range(mean_modelpredsLongRange.shape[0]):\n",
    "  calc = 0\n",
    "  for i in range(len(long_y_test)):\n",
    "    calc += abs(long_y_test[i]-mean_modelpredsLongRange[j][i])\n",
    "  meow_diff_long_differences.append(calc/len(long_y_test))\n",
    "print(meow_diff_long_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b9ddb7-dc63-4149-b9f4-65df7911f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(diff_differences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4c869e-4aaf-4eac-ad70-fc06484bd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"transformer0.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from FNN1_1 import baseline_deviation, baeline_out_deviation, baseline_long_deviation, baseline_relError, absSum\n",
    "baseline_out_deviation = baeline_out_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b244564-e6f9-4c80-b1f1-75cdcbbddffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2.3868892], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "for i in range(len(diff_differences)):\n",
    "  calc = 0\n",
    "  calc += baseline_deviation / (diff_differences[i]**2)\n",
    "  calc += baseline_out_deviation / (diff_out_differences[i]**2)\n",
    "  calc += baseline_long_deviation / (diff_long_differences[i]**2)\n",
    "  calc += baseline_relError / (diff_avRelError[i]**2)\n",
    "  benchmark.append(calc/4)\n",
    "print(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "727be262-7945-429c-adf4-b955b9ae5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = (max_neurons - min_neurons) // neuron_step + 1\n",
    "num_layers = max_layers - min_layers + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f33ee47-656c-401e-9e78-ec7a84f66f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new array to include the means\n",
    "# Add a column for row means and a row for column means (and a corner for the overall mean)\n",
    "benchmark_array = np.array(benchmark).reshape(num_layers, num_neurons)\n",
    "extended_benchmark_array = np.zeros((num_layers + 1, num_neurons + 1))\n",
    "\n",
    "Neurons_means = np.mean(benchmark_array, axis=0)\n",
    "Layers_means = np.mean(benchmark_array, axis=1)\n",
    "\n",
    "# Copy the original benchmark data\n",
    "extended_benchmark_array[:num_layers, :num_neurons] = benchmark_array\n",
    "\n",
    "# Add the row means\n",
    "extended_benchmark_array[:num_layers, num_neurons] = Layers_means\n",
    "\n",
    "# Add the column means\n",
    "extended_benchmark_array[num_layers, :num_neurons] = Neurons_means\n",
    "\n",
    "# Calculate and add the overall mean\n",
    "overall_mean = np.mean(benchmark_array)\n",
    "extended_benchmark_array[num_layers, num_neurons] = overall_mean\n",
    "\n",
    "\n",
    "# Create updated tick labels for the heatmap\n",
    "xticklabels_extended = list(np.arange(min_neurons, max_neurons + 1, neuron_step)) + ['Row Mean']\n",
    "yticklabels_extended = list(np.arange(min_layers, max_layers + 1)) + ['Column Mean']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10)) # Adjust figure size for the extra row/column\n",
    "ax = sns.heatmap(extended_benchmark_array, annot=True, fmt=\".2f\", cmap=\"inferno\",\n",
    "            xticklabels=xticklabels_extended,\n",
    "            yticklabels=yticklabels_extended)\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ax.hlines(y=6, xmin=xmin, xmax=xmax, colors='lightblue', lw=2, linestyle='-')\n",
    "ax.vlines(x=11, ymin=ymin, ymax=ymax, colors='lightblue', lw=2, linestyle='-')\n",
    "plt.ylabel('Number of Layers')\n",
    "plt.xlabel('Number of Neurons per Layer')\n",
    "plt.title('Heatmap of the Benchmarks with Row and Column Means')\n",
    "plt.savefig(\"bigHeatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2678ff-6aa5-44db-aae0-90cf9c8a16c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE in Range P-value: 0.48752391502709524\n",
      "MRE in Range P-value: 0.0008468321691315803\n",
      "MAE out Range P-value: 0.0010608374630298794\n",
      "MRE out Range P-value: 0.00019872829039021343\n",
      "MAE long Range P-value: 0.0009479219448757716\n",
      "Benchmark P-value: 0.13441415336853435\n",
      "\n",
      "Average MAE in Range: 0.8141126370094538\n",
      "Average MRE in Range: 0.30295140301299767\n",
      "Average MAE out Range: 3.970514955102408\n",
      "Average MRE out Range: 0.43386028035445207\n",
      "Average MAE long Range: 2.931803976356983\n",
      "Average benchmark: 2.2023795683112612\n",
      "\n",
      "MAE in Range List: [1.4069653676238547, 0.4197202476640229, 0.38960283006718494, 0.44151914757903343, 1.412755592113173]\n",
      "MRE in Range List: [0.494388567463127, 0.169155473370239, 0.17054126221565868, 0.18981316217291092, 0.49085854984305277]\n",
      "MAE out Range List: [4.879901261476334, 3.483906427572947, 3.159820586479327, 3.5905273668613518, 4.738419133122079]\n",
      "MRE out Range List: [0.5397384083286986, 0.36209918928652807, 0.3342081879140105, 0.3988980343636064, 0.5343575818794168]\n",
      "MAE long Range List: [3.4747628378016606, 2.8516895368269513, 2.3343226260159695, 2.604308853149414, 3.3939360279909203]\n",
      "Benchmark List: [0.7310808569234342, 3.0921326303243326, 4.157048915821371, 2.0282056275206637, 1.0034298109665056]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Initialize lists to store metrics for each bootstrap run\n",
    "MAEinRange_list = []\n",
    "MREinRange_list = []\n",
    "MAEoutRange_list = []\n",
    "MREoutRange_list = []\n",
    "MAElongRange_list = []\n",
    "benchmarks_list = []\n",
    "\n",
    "# Loop through the predictions from each bootstrap run\n",
    "# This assumes the notebook is run with n_bootstrap > 1 for statistical tests\n",
    "for i in range(n_bootstrap):\n",
    "    # Extract predictions for the current run\n",
    "    current_preds_in_range = bootstrap_predsInRange[i]\n",
    "    current_preds_out_range = bootstrap_predsOutRange[i]\n",
    "    current_preds_long_range = bootstrap_predsLongRange[i]\n",
    "\n",
    "    # --- In-Range Metrics ---\n",
    "    diffInRange = np.abs(y_test - current_preds_in_range.flatten())\n",
    "    safe_y_test = np.where(np.isclose(y_test, 0.0), 1.0, y_test)\n",
    "    reldiffInRange = diffInRange / np.abs(safe_y_test)\n",
    "    \n",
    "    mean_mae_in_range = np.mean(diffInRange)\n",
    "    mean_mre_in_range = np.mean(reldiffInRange)\n",
    "    MAEinRange_list.append(mean_mae_in_range)\n",
    "    MREinRange_list.append(mean_mre_in_range)\n",
    "\n",
    "    # --- Out-of-Range Metrics ---\n",
    "    diffOutRange = np.abs(out_y_test - current_preds_out_range.flatten())\n",
    "    safe_out_y_test = np.where(np.isclose(out_y_test, 0.0), 1.0, out_y_test)\n",
    "    reldiffOutRange = diffOutRange / np.abs(safe_out_y_test)\n",
    "\n",
    "    mean_mae_out_range = np.mean(diffOutRange)\n",
    "    mean_mre_out_range = np.mean(reldiffOutRange)\n",
    "    MAEoutRange_list.append(mean_mae_out_range)\n",
    "    MREoutRange_list.append(mean_mre_out_range)\n",
    "\n",
    "    # --- Long-Range Metrics ---\n",
    "    diffLongRange = np.abs(long_y_test - current_preds_long_range.flatten())\n",
    "    mean_mae_long_range = np.mean(diffLongRange)\n",
    "    MAElongRange_list.append(mean_mae_long_range)\n",
    "    \n",
    "    # --- Benchmark Calculation ---\n",
    "    # This part replicates the specific slicing and filtering from the notebook for the benchmark score\n",
    "    \n",
    "    # Specific filter for out-of-range benchmark calculation (from cell 11)\n",
    "    placeholder = absSum(outsideExpr)\n",
    "    indices_with_placeholder_22 = [i for i, val in enumerate(placeholder) if val == 22]\n",
    "    diffOutRange_for_benchmark_run = []\n",
    "    for idx in indices_with_placeholder_22:\n",
    "        diffOutRange_for_benchmark_run.append(np.abs(out_y_test[idx] - current_preds_out_range[idx]))\n",
    "    \n",
    "    meanDiff_OutRange_for_benchmark = np.mean(diffOutRange_for_benchmark_run)\n",
    "\n",
    "    # Specific slice for long-range benchmark calculation (from cell 13)\n",
    "    diffLongRange_for_benchmark_run = []\n",
    "    for j in range(200, 300):\n",
    "         diffLongRange_for_benchmark_run.append(np.abs(long_y_test[j] - current_preds_long_range[j]))\n",
    "\n",
    "    meanDiff_LongRange_for_benchmark = np.mean(diffLongRange_for_benchmark_run)\n",
    "\n",
    "    # Calculate the benchmark score for the current run\n",
    "    benchmark = 0\n",
    "    benchmark += baseline_deviation / (mean_mae_in_range**2) / 4\n",
    "    benchmark += baseline_out_deviation / (meanDiff_OutRange_for_benchmark**2) / 4\n",
    "    benchmark += baseline_long_deviation / (meanDiff_LongRange_for_benchmark**2) / 4\n",
    "    benchmark += baseline_relError / (mean_mre_out_range**2) / 4 # Using the overall MRE for out-of-range\n",
    "    benchmarks_list.append(benchmark)\n",
    "\n",
    "# --- Statistical Analysis and Final Output ---\n",
    "\n",
    "# Perform one-sample t-test against a population mean of 1.\n",
    "# Note: A t-test is only meaningful if n_bootstrap > 1.\n",
    "if n_bootstrap > 1:\n",
    "    stats1, p_value1 = ttest_1samp(MAEinRange_list, popmean=1)\n",
    "    stats2, p_value2 = ttest_1samp(MREinRange_list, popmean=1)\n",
    "    stats3, p_value3 = ttest_1samp(MAEoutRange_list, popmean=1)\n",
    "    stats4, p_value4 = ttest_1samp(MREoutRange_list, popmean=1)\n",
    "    stats5, p_value5 = ttest_1samp(MAElongRange_list, popmean=1)\n",
    "    stats6, p_value6 = ttest_1samp(benchmarks_list, popmean=1)\n",
    "\n",
    "    print(f\"MAE in Range P-value: {p_value1}\")\n",
    "    print(f\"MRE in Range P-value: {p_value2}\")\n",
    "    print(f\"MAE out Range P-value: {p_value3}\")\n",
    "    print(f\"MRE out Range P-value: {p_value4}\")\n",
    "    print(f\"MAE long Range P-value: {p_value5}\")\n",
    "    print(f\"Benchmark P-value: {p_value6}\\n\")\n",
    "else:\n",
    "    print(\"Cannot calculate p-values with n_bootstrap=1. Run more bootstraps for statistical tests.\\n\")\n",
    "\n",
    "\n",
    "# Print average metrics across all runs\n",
    "print(f\"Average MAE in Range: {np.mean(MAEinRange_list)}\")\n",
    "print(f\"Average MRE in Range: {np.mean(MREinRange_list)}\")\n",
    "print(f\"Average MAE out Range: {np.mean(MAEoutRange_list)}\")\n",
    "print(f\"Average MRE out Range: {np.mean(MREoutRange_list)}\")\n",
    "print(f\"Average MAE long Range: {np.mean(MAElongRange_list)}\")\n",
    "print(f\"Average benchmark: {np.mean(benchmarks_list)}\\n\")\n",
    "\n",
    "# Print the lists of metrics for inspection\n",
    "print(f\"MAE in Range List: {MAEinRange_list}\")\n",
    "print(f\"MRE in Range List: {MREinRange_list}\")\n",
    "print(f\"MAE out Range List: {MAEoutRange_list}\")\n",
    "print(f\"MRE out Range List: {MREoutRange_list}\")\n",
    "print(f\"MAE long Range List: {MAElongRange_list}\")\n",
    "print(f\"Benchmark List: {benchmarks_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb4af7-38d6-42a7-829b-83ee1ffcc61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old versions and stuff (TF GPU)",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
