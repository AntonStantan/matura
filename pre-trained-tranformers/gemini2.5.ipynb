{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0708426e-3e8c-4d4e-b33b-7004283aa382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "from google import genai\n",
    "from google.genai.types import HttpOptions, CreateTuningJobConfig, TuningDataset\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1548fc9-a6e8-4b5a-b388-09d506d17e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 2 + 2\n",
      "2543\n",
      "0.0\n",
      "\n",
      "Expressions not in x:\n",
      "-4 - 2 - 3\n",
      "True\n",
      "1457\n",
      "-9.0\n",
      "15\n",
      "-4.0\n",
      "[-5.   1.   1.   0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5]\n",
      "Successfully imported variables!\n"
     ]
    }
   ],
   "source": [
    "# Get the absolute path of the current script's directory\n",
    "current_dir = os.path.dirname(os.path.abspath(\"gemini2.5.ipynb\"))\n",
    "\n",
    "# Get the absolute path of the parent directory (project_folder)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import from GetXY.py\n",
    "from GetXY import x, y\n",
    "\n",
    "# ... rest of your code\n",
    "print(\"Successfully imported variables!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba739629-d9de-4ae9-adc2-0e31b5716e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_input': '[0.0, 0.0, 2.0, 1.0, 2.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]', 'output': '0.0'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Specify the output file name\\nfile_name = \\'my_dataset.jsonl\\'\\n\\n# Write the data to the JSONL file\\nwith open(file_name, \\'w\\') as f:\\n    for entry in dataset:\\n        # The json.dump() method writes a JSON object to a file-like object.\\n        # It\\'s important to add a newline character (\\n) after each object.\\n        json.dump(entry, f)\\n        f.write(\\'\\n\\')\\n\\nprint(f\"Dataset successfully saved to \\'{file_name}\\'\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.tolist()\n",
    "\n",
    "dataset = [\n",
    "    {\n",
    "        'text_input': str(x_item), \n",
    "        'output': str(y_item)\n",
    "    }\n",
    "    for x_item, y_item in zip(x, y)\n",
    "]\n",
    "\n",
    "print(dataset[0])\n",
    "\n",
    "# Specify the output file name\n",
    "file_name = 'my_dataset.jsonl'\n",
    "\n",
    "# Write the data to the JSONL file\n",
    "with open(file_name, 'w') as f:\n",
    "    for entry in dataset:\n",
    "        # The json.dump() method writes a JSON object to a file-like object.\n",
    "        # It's important to add a newline character (\\n) after each object.\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"Dataset successfully saved to '{file_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7fe965-49d5-448b-a336-521a9754f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"),\n",
    "                      api_key = \"\",\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7287789b-3c8b-4bca-b412-67e29f95883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcs_uri='file_name' vertex_dataset_resource=None examples=None\n"
     ]
    }
   ],
   "source": [
    "training_dataset = TuningDataset(\n",
    "    gcs_uri=\"file_name\"\n",
    ")\n",
    "print(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e89606-97d6-47af-95b6-35484c50e223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during the tuning submission: module 'google.generativeai' has no attribute 'tune_model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A_118784\\Desktop\\matura_github\\HuggingFaceEnv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "try:\n",
    "    tuning_job = genai.tune_model(\n",
    "        base_model=\"models/gemini-1.0-pro-001\",\n",
    "        training_dataset=training_dataset,\n",
    "        # Optional, but recommended:\n",
    "        tuned_model_display_name=\"My Numerical Pattern Model\"\n",
    "    )\n",
    "\n",
    "    print(f\"Tuning job submitted successfully. Job name: {tuning_job.name}\")\n",
    "    print(\"You can monitor the job's progress in the Google AI Studio.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the tuning submission: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601de331-7e10-43ff-8795-8eedf7e3b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A_118784\\AppData\\Local\\Temp\\ipykernel_29032\\3427001577.py:1: ExperimentalWarning: The SDK's tuning implementation is experimental, and may change in future versions.\n",
      "  tuning_job = client.tunings.tune(\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for _CreateTuningJobParametersPrivate\ntraining_dataset\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=[{'text_input': '[0.0, 0....0.5]', 'output': '5.0'}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tuning_job = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtunings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-pro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateTuningJobConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtuned_model_display_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFirst Time Fine-Tuner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\matura_github\\HuggingFaceEnv\\Lib\\site-packages\\google\\genai\\_common.py:549\u001b[39m, in \u001b[36mexperimental_warning.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    543\u001b[39m   warning_done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    544\u001b[39m   warnings.warn(\n\u001b[32m    545\u001b[39m       message=message,\n\u001b[32m    546\u001b[39m       category=ExperimentalWarning,\n\u001b[32m    547\u001b[39m       stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    548\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\matura_github\\HuggingFaceEnv\\Lib\\site-packages\\google\\genai\\tunings.py:1294\u001b[39m, in \u001b[36mTunings.tune\u001b[39m\u001b[34m(self, base_model, training_dataset, config)\u001b[39m\n\u001b[32m   1292\u001b[39m       tuning_job.evaluation_config = validated_evaluation_config\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m   operation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tune_mldev\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1299\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m operation.metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m operation.metadata:\n\u001b[32m   1300\u001b[39m     tuned_model_name = operation.metadata[\u001b[33m'\u001b[39m\u001b[33mtunedModel\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\matura_github\\HuggingFaceEnv\\Lib\\site-packages\\google\\genai\\tunings.py:1155\u001b[39m, in \u001b[36mTunings._tune_mldev\u001b[39m\u001b[34m(self, base_model, pre_tuned_model, training_dataset, config)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_tune_mldev\u001b[39m(\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1138\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1142\u001b[39m     config: Optional[types.CreateTuningJobConfigOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1143\u001b[39m ) -> types.TuningOperation:\n\u001b[32m   1144\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Creates a supervised fine-tuning job and returns the TuningJob object.\u001b[39;00m\n\u001b[32m   1145\u001b[39m \n\u001b[32m   1146\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1152\u001b[39m \u001b[33;03m    A TuningJob operation.\u001b[39;00m\n\u001b[32m   1153\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m   parameter_model = \u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_CreateTuningJobParametersPrivate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m      \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m      \u001b[49m\u001b[43mpre_tuned_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_tuned_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m      \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m   request_url_dict: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]\n\u001b[32m   1163\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\matura_github\\HuggingFaceEnv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for _CreateTuningJobParametersPrivate\ntraining_dataset\n  Input should be a valid dictionary or object to extract fields from [type=model_attributes_type, input_value=[{'text_input': '[0.0, 0....0.5]', 'output': '5.0'}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_attributes_type"
     ]
    }
   ],
   "source": [
    "tuning_job = client.tunings.tune(\n",
    "    base_model=\"gemini-2.5-pro\",\n",
    "    training_dataset = dataset,\n",
    "    config=CreateTuningJobConfig(\n",
    "        tuned_model_display_name=\"First Time Fine-Tuner\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf101da-131d-4071-828f-b0e6b29109bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_states = set([\n",
    "    \"JOB_STATE_PENDING\",\n",
    "    \"JOB_STATE_RUNNING\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b907a9-bb52-4506-95de-82048f8d9f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while tuning_job.state in running_states:\n",
    "    print(tuning_job.state)\n",
    "    tuning_job = client.tunings.get(name=tuning_job.name)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62f58c-f3c9-4382-ba3c-d1f94359aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuning_job.tuned_model.model)\n",
    "print(tuning_job.tuned_model.endpoint)\n",
    "print(tuning_job.experiment)\n",
    "# Example response:\n",
    "# projects/123456789012/locations/us-central1/models/1234567890@1\n",
    "# projects/123456789012/locations/us-central1/endpoints/123456789012345\n",
    "# projects/123456789012/locations/us-central1/metadataStores/default/contexts/tuning-experiment-2025010112345678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aae23a-0279-4dd8-b434-51561015bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tuning_job.tuned_model.checkpoints:\n",
    "    for i, checkpoint in enumerate(tuning_job.tuned_model.checkpoints):\n",
    "        print(f\"Checkpoint {i + 1}: \", checkpoint)\n",
    "    # Example response:\n",
    "    # Checkpoint 1:  checkpoint_id='1' epoch=1 step=10 endpoint='projects/123456789012/locations/us-central1/endpoints/123456789000000'\n",
    "    # Checkpoint 2:  checkpoint_id='2' epoch=2 step=20 endpoint='projects/123456789012/locations/us-central1/endpoints/123456789012345'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa7751-dca4-46f0-ab6b-62b1cd2c0513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7f0db-63a9-4b2c-baec-629b078fa748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HuggingFace Environement",
   "language": "python",
   "name": "my_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
